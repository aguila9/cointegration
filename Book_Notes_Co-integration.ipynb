{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on Co-integration, Error Correction, and the Econometric Analysis of Non-Stationary Data\n",
    "by Anindya Banerjee, Juan Dolado, J. W. Galbraith, David Hendry (z-lib.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An equilibrium state is defined as one in which there is no inherent tendency to change.  Equilibria are states to which the sistem is atracted, other things equal.\n",
    "\n",
    "\"Long-run equilibrium\" is also used to denote the equilibrium relationship to which a system converges over time.\n",
    "\n",
    "The present is the long-run outcome of the distant past and, a long-run relationship will often hold 'on average' over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We say that an equilibrium relationship $f(x_1, x_2)=0$ hold between two variable, if the amount $\\epsilon_t = f(x_{1t}, x_{2t})$ by which actual observations deviate from this equilibrium is a median-zero **stationary process**.\n",
    "The short run $\\epsilon_t$ in an equilibrium relationship must have no tendency to grow systematically over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concept of statistical equilibrium is useful in examining equilibrium relationships between vairables tending to grow over time.  If the actual relationship is $x_1 = \\beta x_2$ the discropancy $x_{1t} - b x_{2t}$ will be nonstationary for $b \\neq \\beta$.  Only the true relationship can yield a stationary discrepancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there exists a stable equilibrium $x_1 = \\beta x_2$, the discrepancy ${x_{1t} - \\beta x_{2t}}$ contains useful information since on average the system will move towards that equilibrium.\n",
    "\n",
    "In particular ${x_{1t-1} - \\beta x_{2t-1}}$ represent the previous disequilibrium. It is called *error-correction mechanism* and is included in dynamic regressions. If ${x_{1t-1} - \\beta x_{2t-1}}$ is positive, $x_{1t-1}$ is to high and on avergae we might expect a fall in $x_1$ future periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The practice of exploiting information contained in the current deviation from an equilibrium relationship, in explaining the path of a variable, has benefited from the formalization of the concept of co-integration by Granger (1981) and Engle and Granger (1987)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series is said to be integrated of order 1 $(I(1))$ if, although it is itself non-stationary, the changes in this series form a stationary series. A stationary series is denoted as $(I(0))$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definition of co-integration does require stationarity of the deviation ${x_{1t} - \\beta x_{2t}}$\n",
    "\n",
    "A linear relation yields a stationary deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An *integrated process* is one that can be made stationary by differencing. A discrete process integrated of orde $d$ must be differenced $d$ times to reach stationarity.\n",
    "\n",
    "If $x_t$ is stationary then so is $\\Delta x_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A discrete process integrated of order $d$ must be differenced $d$ times to reach stationarity; that is, $\\Delta^d x_t$ is stationary where the differencing operator $\\Delta^d$ is defined by $(1 - L)^d$\n",
    "\n",
    "Lag operator $L$, is defined by $L^n x_t = x_{t-n}$\n",
    "\n",
    "The first difference is:\n",
    "$$\\Delta x_t = x_t - x_{t-1}$$\n",
    "The second difference is:\n",
    "$$\\Delta^2 x_t = \\Delta x_t - \\Delta x_{t-1} = x_t - 2x_{t-1} + x_{t-2} = (1 - L)^2 x_t$$\n",
    "\n",
    "The process $(1 - L)x_t = \\epsilon_t$, where {$\\epsilon_t$} is a white-noise series, is called a random walk and is a simple example of a process integrated of order 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error-correction model (ECM)**. Error-correction terms were used as a way of capturing adjustments in a dependent variable which depended not on the level of some explanatory variable, but on the extent to which an explanatory variable deviated from an equilibrium relationship with the dependent variable.\n",
    "\n",
    "When the equilibrium relationship is of the form $y^* = \\theta x^*$, then an error-correction term is one such as ($y_t - \\theta x_t$).\n",
    "\n",
    "The error-correction mechanism will be of particular value where the extent of an adjustment to a deviation from equilibrium is especially interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example of the problems that can arise when performing regression with clearly non-stationary series is the problem of *nonsense regression*, or *spurious regression*\n",
    "\n",
    "The standar proof of the consistency of ordinary least squeares regression uses the assumption that with increasing sample information, the sample moments of the data settle down to treir population values. In order to have fixed population moments to which these sample moments converge, the data must be stationey.\n",
    "\n",
    "If we have uncorrelate random walks $x_t$ and $y_t$. that is, neither $x_t$ affects nor is affected by $y_t$, one would expect that the coefficient $\\beta_1$ in {$y_t = \\beta_0 + \\beta_1 X_t + \\epsilon_t$} would converge to zero and the coefficient of determination ($R^2$) would also tend to zero.  However, this is not the case. If two time series are each growing, they may be correlated even though they are increasin for entirely different reasons and by increments that are uncorrelated.\n",
    "\n",
    "Tests based on badly specified models can often be misleading.\n",
    "\n",
    "Although $t-$ and $F-$ statistics fro the null hypotesisof interest are grossly misleading, some information which would suggest that the regression is misspecified is provided by a test for residual autocorrelation.\n",
    "\n",
    "If $x_t$ and $y_t$ where made stationary, the OLS-estimated regression coefficient $\\hat{\\beta_1}$ would converge to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spurios regression Problem**: Regression of an integrated series on another unrelated integrated series produces t-ratios on th slope parameter which indicate a relationship much more often than they should at the nominal test level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Durbin-Watson statistic calculated from the residual of {$y_t = \\beta_0 + \\beta_1 X_t + \\epsilon_t$} converges to zero as the sample size tends to infinity.  When the two series are genuinely related, the DW statistic converges to a non-zero value. DW statistic provides one way of sidciminating between spurious and genuine regression for large samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laws of large numbers guarantee the convergence in probibility of the sample mean to the true mean of the process fro a class of processes that includes stationary time series, but one of the primary facts about integrated processes is that convergence theorems of this type, chere convergence is to constants, generally fail to hold.\n",
    "\n",
    "Analitical results concerning limiting distributions must therefore be based on an extended asymptotic theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since an $I(1)$ series becomes stationary upon being differenced once, it must contain one unit root.\n",
    "\n",
    "A random walk first difference is stationary. By contrast, the underlying data-generating process\n",
    "$$y_t  = \\rho_1 y_{t-1} + u_{1t} \\;\\; \\text{where} \\;\\; \\vert\\rho_1\\vert > 1 \\;\\; \\text{then we have,}$$\n",
    "$$y_t - y_{t-1} = \\Delta y_t = (\\rho_1 - 1)y_{t-1} + u_{1t}$$\n",
    "$\\Delta y_t$, is no longer stationary: it depends not only upon the stationary process $u_{1t}$, but also upon the non-stationary process $y_{t-i}$ (since $\\rho_1 - 1 > 0$). Hence an AR(1) process with a coefficient of 1 is $I(1)$. *But the same process with a coefficient of 1.01 is not,\n",
    "since differencing will not reduce this process to stationarity.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing for unit root**\n",
    "\n",
    "Consider the simplest data-generation process\n",
    "$$y_t  = \\rho y_{t-1} + u_{t} \\; \\text{;} \\;\\; u_t \\sim \\text{IID}(0,\\sigma_u^2) \\; \\text{;} \\;\\; y_0 = 0$$\n",
    "\n",
    "If one were testing the true hypothesis $H_0:\\rho = \\rho_0$ for $\\rho_0 < 1$, the test would be easily performed. Running the regression, the t-statistic $(\\hat{\\rho} - \\rho_0)/\\text{SE}(\\hat{\\rho})$ has, asymptotically, a standard normal distribution and can be compared with tables of significance points for $N(0,1)$. In small samples the statistic is approximately t-distributed, although the coefficient estimate $\\hat{\\rho}$ is biased downward slightly. \n",
    "\n",
    "For $\\rho_o = 1$, however, this result no longer holds. The distribution of the test statistic just given is not asymptotically normal, or even symmetric. Tables of critical values have been tabulated by D. A. Dickey and are reported in, e.g. Fuller (1976).\n",
    "\n",
    "We can now consider applying a test for $\\rho = 1$ using the t-statistic, as long as we are aware that the distribution of the statistic is non-standard, and so avoid making the mistake of applying t- or normal tables, significance points tabulated by Dickey and Fuller can be used in their place to provide a valid test.\n",
    "\n",
    "Dickey and Fuller test was the first form of 'unit-root test' to have been developed. Its main potential disadvantage lies in the fact that it is based upon the assumption that the specific data-generation process holds precisely under the null.\n",
    "\n",
    "Augmented Dickey-Fuller (ADF) tests, the aim is to use lagged changes in the dependent variable to capture autocorrelated omitted variables which would otherwise, by default, appear in the (necessarily autocorrelated) error term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables hypothesized to be linked by some theoretical economic relationship should not diverge from each other in the long run. Such variables may drift apart in the short run or because of seasonal effects. If they were to diverge without bound,\n",
    "an equilibrium relationship among such variables could not be said to exist. 'Co-integration' may be viewed as the statistical expression of the nature of such equilibrium relationships.\n",
    "\n",
    "The concept of co-integration is a powerful one because it allows us to describe the existence of an equilibrium, or stationary, relationship among two or more time-series, each of which is individually nonstationary.\n",
    "\n",
    "To transform an integrated series to achieve stationarity, we must difference it at least once. However, a linear combination of series may have a lower order of integration than any one of them has individually. *In this case, the variables are said to be co-integrated*\n",
    "\n",
    "For example, if {$x_t$} and {$y_t$} are integrated of order 1 ($I(1)$) and are also co-integrated, then {$\\Delta x_t$}, {$\\Delta y_t$}, and {$x_t + \\alpha y_t$}, for some $\\alpha$, are all stationary series.\n",
    "\n",
    "It is interesting to note that in the bivariate case we have the added bonus that this equilibrium relationship, if such a relationship exists, is *unique*.\n",
    "\n",
    "There are at least three reasons for regarding the concept of cointegration as central to econometric modelling with integrated variables:\n",
    "\n",
    "1. The concept formalizes the link among variables of higher orders of integration, for which some linear combination is of a lower order of integration.\n",
    "2. Regressions involving levels of time series of non-stationary variables make sense if and only if these variables are co-integrated (Meaningful versus spurious regression).\n",
    "3. A set of co-integrated variables is known to have, among other representations, an error-correction representation.\n",
    "\n",
    "Error-correction mechanisms (ECMs) are intended to provide a way of combining the advantages of modelling both levels and differences. In an error-correction model the dynamics of both short-run (changes) and long-run (levels) adjustment processes are modelled simultaneously.\n",
    "\n",
    "The theory of co-integration provides a unified framework for the analysis of ECMs and of time series in which the variables share one or more stochastic trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEFINITION 1.** (adapted from Engle and Granger 1987). The components of the vector $\\boldsymbol{x}_t$ are said to be co-integrated of order $d$, $b$, denoted $\\boldsymbol{x}_t \\sim \\text{Cl}(d, b)$, if ($i$) $\\boldsymbol{x}_t$ is $I(d)$ and ($ii$) there exists a non-zero vector $\\alpha$ such that $\\alpha'\\boldsymbol{x}_t \\sim I(d - b)$, $d \\geq b > 0$. The vector $\\alpha$, is called the co-integrating vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If x, has n > 2 components, then there may be more than one co-integrating vector; it is possible for several equilibrium relationships to govern the joint evolution of the variables.\n",
    "\n",
    "If there exist exactly $r$ linearly independent co-integrating vectors with $r \\leq n - 1$, then these can be gathered into an $n x r$ matrix $\\alpha$. The rank of $\\alpha$ will be $r$ and is called the co-integrating rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEFINITION 2.** A vector time-series $\\boldsymbol{x}_t$ has an error-correction representation if it can be expressed as\n",
    "$$\\boldsymbol{A}(L)(1-L)\\boldsymbol{x}_t = -\\gamma\\boldsymbol{z}_{t-1} + \\boldsymbol{\\omega}_t$$\n",
    "Where $\\boldsymbol{\\omega}_t$ is a stationary multivariate disturbance with $\\boldsymbol{A}(0)=I_n$, $\\boldsymbol{A}(1)$ having only finite elements,  $\\boldsymbol{z}_{t}=\\alpha'\\boldsymbol{x}_t$ and $\\gamma$ is a non-zero vector. For the case where $d = b = 1$, and with co-integrating rank r."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error-correction representation has the special advantage of separating the long-run and the short-run responses. It is also an important part of what has come to be known as the Engle-Granger two-step procedure. A small\n",
    "modification of the error-correction representation provides the interimmultiplier representation which has been used by Johansen (1988) to develop a maximum-likelihood estimator of the dimension of the cointegration space. Likelihood-ratio tests can be used to determine empirically the value of r, the number of co-integrating vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Engle and Granger (1987) two-step estimator** for models involving co-integrated variables.\n",
    "1. First step, the parameters of the co-integrating vector are estimated by running the static regression in the levels of the variables.\n",
    "2. Second step, the estimated co-integrating vector are used in the error-correction form.\n",
    "Both steps require only OLS, and the results may be shown to be consistent for all the parameters. In particular, the estimates of the parameters in the first step converge to their probability limits at rate $T$ while the elements of the vector multiplying the error-correction term, in the second step, converge at the usual asymptotic rate of $\\sqrt{T}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a static regression $y_t = \\alpha X_t + v_t$.\n",
    "\n",
    "$\\hat{\\alpha}$ converges to $\\alpha$ at a rate of $O_p(T)$ and not at the usual rate of $O_p(\\sqrt{T})$. It is this rapid convergence of the estimates of the coefficients that is used by Engle and Granger to affirm that the asymptotic results for estimation of dynamic models with $I(1)$ variables will be the same whether a is estimated or known.\n",
    "\n",
    "If {$x_t$} and {$y_t$} are co-integrated, then $y_{t-1} - \\alpha x_{t-1}$ is $I(0)$ and can be included in the ECM model as if $\\alpha$ were known (that is, the sampling variance of $\\hat{\\alpha}$ can be ignored).\n",
    "\n",
    "If {$x_t$} and {$y_t$} are not co-integrated, we have the spurios regression problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THEOREM (Engle and Granger 1987).** The two-step estimator of a single equation of an error-correction system with one co-integrating vector, obtained by taking the estimate $\\hat{\\alpha}$ of $\\alpha$ from the static regression in place of the true value for estimation of the error-correction form at a second stage, will have the same limiting distribution as the maximum-likelihood estimator using the true value of $\\alpha$. Least-squares standard errors in the second stage will provide consistent estimates of the true standard errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest tests for co-integration proposed by Engle and Granger, test for the existence of a unit root in the residuals of the static regression.\n",
    "\n",
    "To estimate the single co-integrating vector $\\boldsymbol{\\alpha}$ using the static model\n",
    "$$\\boldsymbol{\\alpha}'\\boldsymbol{x}_t = u_t$$\n",
    "Consider the bivariate case, where\n",
    "$$\\boldsymbol{x}_t = (y_t,z_t)'$$\n",
    "As $\\beta$ is unknown, it must be estimated (e.g.) from the static regression of $y_t$ on $z_t$. The test is based on the null hypothesis of no co-integration, with the critical values for the test statistics calculated to ensure the appropriate probability of rejection of the null hypothesis.\n",
    "The co-integration tests are based on the estimated, or derived, residual series\n",
    "$$\\hat{u_t} = y_t + \\hat{\\beta}z_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the most widely used tests of co-integration have been the co-integrating regression Durbin-Watson test (CRDW), the Dickey-Fuller test (DF), and the augmented Dickey-Fuller test (ADF).\n",
    "\n",
    "Engle and Granger (1987) emphasize the robustness to changes in the data-generation process of the ADF critical values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
